# Ã… Energi - Uforskning av datasett 2025

**Project information in English:** [README-ENGLISH.md](README-ENGLISH.md)

## Introduksjon  

Dette prosjektet utforsker tre forskjellige maskinlÃ¦ringsutfordringer, som spenner fra grunnleggende funksjonsapproksimasjon til kompleks sanntidsprognosering. Vi starter med en demonstrasjon av en MLP med PyTorchs og predikerer sinus-kosinus-funksjon, etterfulgt av en analyse av tidsserieprognosering pÃ¥ et lite datasett, der vi sammenligner dype nevrale nettverk med klassiske autoregressive modeller. Til slutt hÃ¥ndterer vi et storskala vannkraftdatasett og evaluerer om et nÃ¸ye justert nevralt nettverk kan overgÃ¥ tradisjonelle gradient-boosting-modeller i en multi-output regresjonsoppgave.

----

# 1. MLP Sinus-Cosinus â€“ regresjon

En rask demonstrasjon av bruk av **PyTorch** for Ã¥ tilpasse en 2D sinus-cosinus-funksjon ved hjelp av to forskjellige Multi-Layer Perceptron (MLP)-arkitekturer:

- **Liten MLP** (moderat kapasitet)  
- **Stor MLP** (hÃ¸y kapasitet, for Ã¥ overtilpasse og fange opp fine detaljer)

![Sinus Cos Overfitting Demo](assets/img/1-sincos.png)

# **2. Tidsserieprognoser med smÃ¥ datasett - Krig mot autoregressoren**  

**_Vi forsÃ¸ker Ã¥ utfordre klassiske autoregressive modeller ved hjelp av dyp lÃ¦ring pÃ¥ et lite datasettâ€”og det var en tung kamp._**  

![Prediksjonstidslinje](assets/img/2_predicted.png)  

## 3. Stor vannkraftmodellering - MLPs hevn!

**_Etter Ã¥ ha utforsket tidsserieprognosering pÃ¥ et lite datasett, vendte vi oppmerksomheten mot en betydelig stÃ¸rre utfordring â€“ et vannkraftdatasett fra Ã… Energi, med millioner av rader og flere mÃ¥lvariabler. MÃ¥let vÃ¥rt var Ã¥ finne ut om et nÃ¸ye justert nevralt nettverk kunne overgÃ¥ tradisjonelle gradient-boosting-modeller i en kompleks multi-output regresjonsoppgave. Underveis hÃ¥ndterte vi dimensjonalitetsproblemer, optimaliserte hyperparametere og sammenlignet modellprestasjoner for Ã¥ finne den mest effektive tilnÃ¦rmingen._**

![Vannkraftplot](assets/img/3-mlp.png)

----

## Indeks:

- [1. MLP Sinus-Cosinus-regresjon](#1-mlp-sinus-cosinus-regresjon) 
- [2. Tidsserieprognoser med smÃ¥ datasett â€“ Krig mot autoregressoren](#2-tidsserieprognoser-med-smÃ¥-datasett--krig-mot-autoregressoren) 
- [3. Stor vannkraftmodellering - MLPs hevn!](#3-stor-vannkraftmodellering--mlps-hevn)  



# 1. MLP Sinus-Cosinus-regresjon

En rask demonstrasjon av bruk av **PyTorch** for Ã¥ tilpasse en 2D sinus-cosinus-funksjon ved hjelp av to forskjellige Multi-Layer Perceptron (MLP)-arkitekturer:

- **Liten MLP** (moderat kapasitet)  
- **Stor MLP** (hÃ¸y kapasitet, for Ã¥ overtilpasse og fange opp fine detaljer)

![Sinus Cos Overfitting Demo](assets/img/1-sincos.png)

## Oversikt

1. **Data**  
   Vi har $(x, i)$-par og et mÃ¥l $z = \sin(\cos(x)) + \sin(\cos(i))$.  
   - Inndata er lagret i `data/X_sincos.txt`
   - MÃ¥lverdier er lagret i `data/y_sincos.txt`
   - Data levert av Ã… Energi.

2. **Modeller**  
   - **SmallMLP**: 2 â†’ 100 â†’ 100 â†’ 1 (med ReLU-aktiveringer)  
   - **LargeMLP**: 2 â†’ 100 â†’ 500 â†’ 500 â†’ 100 â†’ 1 (med ReLU-aktiveringer)

3. **Trening**  
   - Vi bruker **MSE Loss** og **Adam Optimizer** i PyTorch.  
   - **LargeMLP** er bevisst overparameterisert for Ã¥ tilpasse (og til og med overtilpasse) dataene svÃ¦rt godt.

4. **Resultater**  
   - Vi sammenligner den sanne funksjonen med prediksjoner fra begge MLP-ene i en 3D-plot.

![Sinus Cos Overfitting Demo](assets/img/1-sincos.png)

> *Fra venstre til hÃ¸yre*:  
> **(1)** Sann funksjon  
> **(2)** Prediksjoner fra liten MLP  
> **(3)** Prediksjoner fra stor MLP

## Kom i gang

1. **Installer avhengigheter**  
   ```bash
   pip install torch matplotlib numpy
   ```
2. **KjÃ¸r scriptet**  
   ```bash
   python 1-sincos.py
   ```
   - Juster hyperparametere (epoker, lÃ¦ringsrate) om Ã¸nskelig.

3. **Plotting**  
   Scriptet viser automatisk et 3D-overflateplot for Ã¥ sammenligne prediksjonene.

## LÃ¦rdommer

- **SmÃ¥ vs. store modeller**: Et stÃ¸rre nettverk kan tilnÃ¦rme mÃ¥lfunksjonen svÃ¦rt nÃ¸yaktig, men kan overtilpasse dersom datagrunnlaget er begrenset.  
- **Visualisering**: 3D-overflateplott hjelper oss med Ã¥ visuelt vurdere hvor godt modellen fanger opp den underliggende funksjonen.  
- **PyTorch**: Viser hvor enkelt det er Ã¥ bygge og trene MLP-er pÃ¥ egendefinerte data med bare noen fÃ¥ linjer Python-kode.

----


# **2. Tidsserieprognoser med smÃ¥ datasett â€“ Krig mot autoregressoren**  

**_Vi forsÃ¸ker Ã¥ utfordre klassiske autoregressive modeller ved hjelp av dyp lÃ¦ring pÃ¥ et lite datasettâ€”og det var en tung kamp._**  

![Prediksjonstidslinje](assets/img/2_predicted.png)  

## **Oversikt**  

Dette prosjektet utforsker forskjellige tilnÃ¦rminger til Ã¥ forutsi en daglig tidsserie med kun **~4000 observasjoner** (etter Ã¥ ha tatt hensyn til lag-funksjoner). MÃ¥let var Ã¥ undersÃ¸ke om moderne dyp lÃ¦ringâ€”LSTMer og Transformereâ€”kunne overgÃ¥ klassiske statistiske metoder i en situasjon med lite data.  

Vi testet fire modeller:  

1. **Naiv AR**: Den enkleste baselinenâ€”antar at dagens verdi vil vÃ¦re den samme som i gÃ¥r.  
2. **AR(5)**: En lineÃ¦r autoregressiv modell som bruker de siste fem dagene for Ã¥ forutsi neste dag.  
3. **LSTM**: Et rekurrent nevralt nettverk trent pÃ¥ sekvenser av 30 dager.  
4. **Transformer**: En selvoppmerksomhetsmodell som ogsÃ¥ bruker et 30-dagers vindu.  

### **Vant dyp lÃ¦ring?**  

Ikke denne gangen. Med bare noen fÃ¥ tusen datapunkter og kun tre eksogene variabler (`x1, x2, x3`), slet de nevrale nettverkene med Ã¥ finne meningsfulle mÃ¸nstre. De autoregressive modellene, spesielt AR(5), presterte betydelig bedre fordi:  

- Datasettet er **svÃ¦rt lite** (~4000 rader), noe som begrenser lÃ¦ringskapasiteten til dype modeller.  
- De eksogene variablene har **svak forklaringskraft**, noe som betyr at de ikke bidrar mye til prognosen.  
- Tidsserien i seg selv er **sterkt autoregressiv**, noe som betyr at tidligere verdier alene gir et sterkt prediktivt signalâ€”noe de enklere AR-modellene hÃ¥ndterer godt.  

## **Endelige resultater**  

| Modell       | MAE  | MSE  |  
|-------------|------|------|  
| **Naiv AR**  | **2.626**  | **19.377**  |  
| **AR(5)**     | **2.466**  | **17.183**  |  
| LSTM         | 4.930  | 59.427  |  
| Transformer  | 5.853  | 70.126  |  

BÃ¥de LSTM og Transformer ble klart slÃ¥tt av de naive og AR(5)-modellene. De dype lÃ¦ringsmodellene hadde nesten **dobbelt sÃ¥ hÃ¸y MAE** og **tre til fire ganger hÃ¸yere MSE**. En klar seier for den klassiske tilnÃ¦rmingen i dette tilfellet.  

---

## **Viktige grafer**  

### **Prediksjonstidslinje**  

Denne grafen sammenligner faktiske og predikerte verdier over tid. Jo nÃ¦rmere en modells prediksjoner fÃ¸lger de virkelige verdiene, desto bedre presterer den.  

ðŸ“Œ **Hva du bÃ¸r se etter:**  
- Hvilke modeller ligger nÃ¦rmest de faktiske verdiene? Her gjÃ¸r de autoregressive modellene en langt bedre jobb.  
- Henger noen modeller konsekvent etter eller overpredikerer mÃ¥let? Det er ingen systematisk forsinkelse, noe som indikerer at alt er satt opp riktig og at hyperparametrene er rimelige.  
- Hvor mye stÃ¸y introduserer LSTM og Transformer sammenlignet med AR(5)? Svaret er betydelig stÃ¸y og tilfeldige topperâ€”datasettet er for lite til at nevrale nettverk kan skinne!  

![Prediksjonstidslinje](assets/img/2_predicted.png)  

### **Absolutt feil over tid**  

Denne grafen viser hvordan hver modells absolutte feil utvikler seg over tid. Den hjelper med Ã¥ identifisere perioder hvor modellene sliter mest.  

ðŸ“Œ **Hva du bÃ¸r se etter:**  
- Er det spesifikke tidsperioder hvor feilene Ã¸ker kraftig? De stÃ¸rste toppene sammenfaller med store bevegelser i $y$, og fordi datasettet ikke inneholder nok forklaringskraft, gjÃ¸r LSTMer og Transformere store feil.  
- GjÃ¸r Ã©n modell konsekvent stÃ¸rre feil enn de andre?  
- Viser dype lÃ¦ringsmodeller ustabil eller uforutsigbar atferd?  

![Feiltidslinje](assets/img/2_error_timeline.png)  

### **MAE- og MSE-sammenligning**  

Disse sÃ¸ylediagrammene gir en direkte numerisk sammenligning av hvor godt hver modell presterte.  

- **MAE (Mean Absolute Error)** viser gjennomsnittsstÃ¸rrelsen pÃ¥ feilene pÃ¥ en intuitiv mÃ¥te.  
- **MSE (Mean Squared Error)** gir stÃ¸rre vekt til store feil, noe som gjÃ¸r den mer fÃ¸lsom for ekstreme avvik.  

ðŸ“Œ **Hva du bÃ¸r se etter:**  
- AR(5)-modellen oppnÃ¥r lavest MAE og MSEâ€”vinneren av denne utfordringen.  
- LSTM og Transformer har betydelig hÃ¸yere feil, noe som viser at de sliter med det begrensede datasettet.  
- Den naive modellen presterer overraskende godt, noe som viser hvor sterkt autoregressiv tidsserien er.  

**MAE-sammenligning:**  
![MAE](assets/img/2-MAE.png)  

**MSE-sammenligning:**  
![MSE](assets/img/2-MSE.png)  

---

## **Hvordan kjÃ¸re koden**  

1. Installer avhengigheter:  
   ```bash
   pip install numpy pandas matplotlib torch scikit-learn
   ```
2. KjÃ¸r hovedskriptet:  
   ```bash
   python 2-tahps.py
   ```
3. Sjekk konsollutdata og genererte grafer.  

---

## **Konklusjon**  

Til tross for vÃ¥re beste forsÃ¸k, **vant ikke dyp lÃ¦ring denne kampen**â€”men det er ikke overraskende. AR(5) og til og med den naive modellen presterte godt fordi tidligere verdier alene inneholdt nok prediktiv informasjon.  

Imidlertid, i et scenario med **mer data** og **sterkere eksogene variabler**, kunne LSTM og Transformer ha gjort det bedre. ForelÃ¸pig fremhever dette prosjektet en viktig lÃ¦rdom innen tidsserieprognoser: **noen ganger er det enkleste ogsÃ¥ det beste.**  

Vil du eksperimentere? PrÃ¸v Ã¥ legge til flere funksjoner, justere hyperparametere eller bruke forskjellige arkitekturer for Ã¥ se om du kan vippe vektskÃ¥len i favÃ¸r av dyp lÃ¦ring!  

---

# 3. Stor vannkraftmodellering â€“ MLPs hevn!

> **MÃ¥l:** Forutsi flere mÃ¥lvariabler (y1..y4) fra 10 inngangsvariabler (x1..x10).  
> **Data:** Levert av Ã… Energi, med millioner av rader med driftslogger (vi antar).

## Innholdsfortegnelse

1. [Oversikt](#oversikt)  
2. [Modeller](#modeller)  
   - [LineÃ¦r regresjon](#lineÃ¦r-regresjon)  
   - [XGBoost](#xgboost)  
   - [Multi-Layer Perceptron (MLP)](#multi-layer-perceptron-mlp)  
3. [Resultater](#resultater)  
4. [Fremtidige forbedringer](#fremtidige-forbedringer)  
5. [Repository-struktur](#repository-struktur)

---

## Oversikt

Vi testet tre hovedmetoder for Ã¥ finne ut hvilken som best forutsier vÃ¥re fire mÃ¥lvariabler:

1. En klassisk **lineÃ¦r regresjonsmodell** som baseline.  
2. En **trebasert ensemble-metode**: **XGBoost**.  
3. En **nevralt nettverkstilnÃ¦rming** med en multi-output **MLP** i PyTorch.

Alle skriptene genererer **metrikker** som RMSE (Root Mean Squared Error) og MAE (Mean Absolute Error). Vi brukte en trenings-/testsplit pÃ¥ 80/20 og evaluerte ytelsen til hver metode.

---

## Modeller

### LineÃ¦r regresjon

Vi brukte en enkel **multi-output lineÃ¦r modell**: for hver mÃ¥lvariabel (y1..y4) forsÃ¸ker den Ã¥ tilpasse en lineÃ¦r funksjon av x1..x10. Ikke overraskende gjorde lineÃ¦r regresjon det greit, men den fanget ikke opp komplekse sammenhenger. VÃ¥r beste MSE lÃ¥ rundt 0,06â€“0,07 for de fleste mÃ¥lene, noe som tilsvarer en RMSE pÃ¥ omtrent 0,24â€“0,28. Flott for tolkbarhet, men ikke for minimalt feilnivÃ¥.

**Viktig skript**: [`3-vannkraft-linreg.py`](3-vannkraft-linreg.py)

### XGBoost

**XGBoost** (eXtreme Gradient Boosting) er kjent for Ã¥ vÃ¦re sterkt pÃ¥ tabulÃ¦re data â€“ ofte bedre enn nevrale nettverk. Vi brukte **RandomizedSearchCV** for Ã¥ finne optimale hyperparametere som `max_depth`, `learning_rate`, `subsample`, osv. for hver mÃ¥lvariabel.

**HÃ¸ydepunkter**:
- OppnÃ¥dde RMSE rundt **0,05â€“0,07** for y1..y4.
- Ekstremt rask pÃ¥ CPU med `tree_method='hist'`.
- SlÃ¥r vanligvis lineÃ¦re modeller pÃ¥ ikke-lineÃ¦re data.

**Viktig skript**: [`3-vannkraft-xgboost.py`](3-vannkraft-xgboost.py)

### Multi-Layer Perceptron (MLP)

"Noen sier nevrale nettverk er overvurdert pÃ¥ strukturerte data!" Vi ville se om en godt justert MLP kunne matche eller overgÃ¥ XGBoost. Vi bygde en **multi-output** MLP i PyTorch med `output_dim=4`, slik at den forutsier y1..y4 samtidig.

Etter en grundig hyperparametertesting (til tross for noen dokumentasjonsproblemer med skorch i Python 3.13), fant vi en optimal konfigurasjon med:

- **2** skjulte lag  
- **512** nevroner i hvert lag  
- **0,01** dropout  
- En lÃ¦ringsrate pÃ¥ **0,001**  
- Trening i **134** epoker  

**Viktig skript**: [`3-vannkraft-mlp.py`](3-vannkraft-mlp.py)

---

## Resultater

### LineÃ¦r regresjon vs. XGBoost vs. MLP

| Metode      | y1 RMSE  | y2 RMSE  | y3 RMSE  | y4 RMSE  | Kommentarer                              |
|-------------|----------|----------|----------|----------|-------------------------------------------|
| **LinearReg** | ~0,25  | ~0,24   | ~0,28   | ~0,27   | Grei baseline, men ikke best              |
| **XGBoost**   | ~0,07  | ~0,06   | ~0,06   | ~0,05   | Sterk ytelse, lett Ã¥ justere              |
| **MLP**       | ~0,06  | ~0,045  | ~0,043  | ~0,033  | Overgikk faktisk XGBoost i disse testene! |

> **Merk:** Tabellen ovenfor er en rask oppsummering. Tallene er basert pÃ¥ endelige testresultater (se nedenfor).

**Grafer**  
![LineÃ¦r regresjon](assets/img/3-linreg.png)  
![XGBoost](assets/img/3-xgboost.png)  
![Multilayer perceptron](assets/img/3-mlp.png)  

**Detaljerte metrikker**:

- **XGBoost**  
  ![Linear regression](assets/img/3-linreg-mse.png)
  - y1: MSE=0.005233 (RMSE=0.0723), MAE=0.0364  
  - y2: MSE=0.003901 (RMSE=0.0625), MAE=0.0297  
  - y3: MSE=0.003477 (RMSE=0.0590), MAE=0.0202  
  - y4: MSE=0.002654 (RMSE=0.0515), MAE=0.0170  

- **MLP** 
  ![XGBoost](assets/img/3-xgboost-mse.png) 
  - y1: MSE=0.003587 (RMSE=0.0599), MAE=0.0231  
  - y2: MSE=0.002085 (RMSE=0.0457), MAE=0.0213  
  - y3: MSE=0.001892 (RMSE=0.0435), MAE=0.0129  
  - y4: MSE=0.001143 (RMSE=0.0338), MAE=0.0128  

- **Linear Regression**  
  ![Multilayer perceptron](assets/img/3-mlp-mse.png)
  - y1: MSE=0.064769 (RMSE=0.2545), MAE=0.2177  
  - y2: MSE=0.057551 (RMSE=0.2399), MAE=0.2000  
  - y3: MSE=0.075656 (RMSE=0.2751), MAE=0.2381  
  - y4: MSE=0.071608 (RMSE=0.2676), MAE=0.2291  

**Konklusjon**: MLP presterer litt bedre enn XGBoost i de endelige kjÃ¸ringene â€“ noe uvanlig for rent tabulÃ¦re data, men det viser at med tilstrekkelig hyperparameterjustering og muligens det store datasettet, kan MLP utmerke seg.

---

## Fremtidige forbedringer

Vi kan forbedre modellene ytterligere ved Ã¥:

1. **Bruke PCA**  
   - Korrelasjonsanalysen viste noen redundante variabler. Redusere dimensjonaliteten til ~4â€“6 hovedkomponenter kan forbedre generalisering.
2. **Utforske flere modeller**  
   - Kanskje **LightGBM** eller **CatBoost** for bedre GPU-utnyttelse eller innebygd stÃ¸tte for kategoriske variabler.
3. **Domeneinnsikt**  
   - Kunnskap om hydrokraftens fysiske sammenhenger kan hjelpe oss med feature engineering eller modellforbedringer.
4. **Dypere nevrale nettverk eller transformere**  
   - Ikke alltid fordelaktig for tabulÃ¦re data, men spesialiserte modeller som TabNet eller en tilpasset Transformer kan avslÃ¸re skjulte mÃ¸nstre.
5. **Mer omfattende hyperparametertesting**  
   - Med 25+ millioner rader kunne vi bruke HPC eller GPU-ressurser for en grundigere sÃ¸k.

---

## Repository-struktur

```
.
â”œâ”€â”€ hyperparam_tuning/
â”‚   â”œâ”€â”€ hyper_xgboost.py        # Kode for Ã¥ finne beste XGBoost-parametere
â”‚   â”œâ”€â”€ hyper_mlp.py            # PyTorch MLP hyperparameter-sÃ¸k
â”‚   â””â”€â”€ ... andre eksperimenter
â”œâ”€â”€ 3-vannkraft-linreg.py       # Endelig multi-output lineÃ¦r regresjonsmodell
â”œâ”€â”€ 3-vannkraft-xgboost.py      # Endelig XGBoost-modell + grafer
â”œâ”€â”€ 3-vannkraft-mlp.py          # Endelig MLP-modell + grafer
â”œâ”€â”€ data/
â”‚   â””â”€â”€ vannkraft_data.txt      # Datasettet (tab-separert)
â””â”€â”€ README.md                   # Denne filen (med resultater + analyse)
```

Vi hÃ¥per dette prosjektet demonstrerer vÃ¥r kompetanse innen **modellering av tabulÃ¦re data** og vÃ¥r vilje til Ã¥ eksperimentere med ulike metoder. Vi hadde det gÃ¸y med Ã¥ jakte pÃ¥ bedre RMSE-verdier (hvem skulle tro at 0,05 â†’ 0,033 kunne fÃ¸les sÃ¥ tilfredsstillende?).


ðŸ’¬ **SpÃ¸rsmÃ¥l eller tilbakemeldinger?**  
Ta gjerne kontakt eller opprett en issue â€“ diskuterer gjerne prognoser og maskinlÃ¦ring!

---
